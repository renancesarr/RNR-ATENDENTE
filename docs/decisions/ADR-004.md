# ADR-004: Estratégia de Debounce para Respostas Automáticas

- **Status**: Accepted
- **Context Timestamp**: 2025-10-12

## Contexto
A Evolution API dispara webhooks a cada mensagem recebida, e nosso orquestrador de respostas (OpenAI + workflows internos) pode receber múltiplos eventos em sequência (ex.: digitação parcelada, anexos sucessivos). Precisamos evitar respostas redundantes que aumentam o custo de tokens e pioram a experiência do usuário. O backlog define um intervalo de debounce entre 30 s e 120 s conforme o contexto da conversa.

## Fatores de decisão
- Manter TTFR baixo sem inundar o lead com múltiplas mensagens seguidas.
- Reduzir custo de chamadas OpenAI, especialmente quando o usuário envia mensagens em rajadas curtas.
- Preservar flexibilidade para canais diferentes (texto vs. mídia) e tipos de fluxo (qualificação vs. follow-up).
- Implementação simples no MVP, passível de rodar junto ao serviço de orquestração.

## Opções consideradas
1. **Debounce fixo de 30 s para todas as conversas**  
   - Prós: fácil implementação, comportamento previsível.  
   - Contras: pode atrasar respostas quando o lead envia uma única mensagem e espera retorno imediato; inflexível para fluxos longos.  
   - Impacto: custo baixo; risco de experiência ruim em conversas puntuais.
2. **Debounce adaptativo com janela deslizante 30–120 s** (peso nos últimos eventos)  
   - Prós: ajusta o atraso conforme frequência de mensagens; mantém rapidez quando necessário e retarda quando há spam.  
   - Contras: demanda cálculo de heurística (peso por tipo de mensagem, prioridade).  
   - Impacto: custo moderado de implementação; melhor equilíbrio TTFR vs. sobrecarga.
3. **Fila de orquestração com batching em RabbitMQ (agrupando N eventos antes da IA)**  
   - Prós: garante ordenação; possibilidade de processar lotes; desacopla do tempo.  
   - Contras: complexidade maior (ack reordenado, timers por fila); pode atrasar muito respostas.  
   - Impacto: custo operacional maior; manutenção elevada.

## Decisão
Adotamos a opção 2: debounce adaptativo 30–120 s com janela deslizante por `conversation_id`. Regras:
- Base de 30 s após qualquer `message_received`.
- Se o lead enviar ≥3 mensagens em 60 s, estendemos o próximo debounce para 60 s.
- Caso o volume ultrapasse 6 eventos em 2 minutos ou envolva anexos grandes, elevamos para até 120 s antes de chamar a IA novamente.
- Eventos de alta prioridade (palavras-chave de urgência, cancelamento, “atendente humano”) ignoram o debounce e são roteados imediatamente para IA ou handoff humano.

Persistimos em Redis um registro `conversation_debounce_state` com timestamps e contadores; o serviço de orquestração consulta antes de disparar nova resposta. Após expiração de 5 minutos sem novas mensagens, o estado é limpado.

## Consequências
- Positivo: reduz respostas redundantes e custo de tokens; melhora contexto agregando múltiplas entradas antes da IA.  
- Positivo: flexível para diferentes padrões de usuário; TTFR inicial continua dentro da meta (primeiro contato responde sem atraso extra).  
- Risco: regras heurísticas podem precisar ajustes conforme dados reais; se mal calibradas, podem atrasar respostas legítimas.  
- Mitigação: registrar métricas (número de respostas suprimidas, tempo médio adicional) e permitir override por operador.

## Follow-up
- [ ] Implementar módulo de debounce no orquestrador (armazenando estado em Redis).  
- [ ] Adicionar métricas Prometheus: `debounce_delay_seconds`, `debounce_buckets`, `debounce_overrides_total`.  
- [ ] Criar endpoint/admin para liberar manualmente uma conversa do debounce.  
- [ ] Revisar heurística mensalmente com base nos dados de conversas reais.
